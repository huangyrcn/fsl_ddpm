# =========================
# 基础配置（数据 & Encoder）
# =========================
dataset_name: Letter_high
baseline_mode: null
seed: 42

# few-shot 设定
N_way: 4
K_shot: 3
query_size: 10

# 训练稳定性
patience: 5
dropout: 0.5
batch: 128

# GNN Encoder
gin_layer: 3
gin_hid: 128
aug1: node_drop
aug2: feature_mask
t: 0.2
lr: 0.001
weight_decay: 1.0e-7
eval_interval: 200
epoch_num: 1000
use_select_sim: false
save_test_emb: true

# prompt（此项目默认不用）
num_token: 1
use_prompt: false

# 设备
device: cuda

# 数据维度（保持与你数据一致）
train_classes_num: 13
test_classes_num: 4
node_fea_size: 2
sample_input_size: 256

# 图池化
graph_pooling_type: sum

# Encoder
use_pretrained_encoder: true
encoder_ckpt_path: ./savepoint/Letter_high_encoder.pkl

# =========================
# LDM 训练相关
# =========================
# 为了训练这套 LDM，把预训练开关关掉
use_pretrained_ldm: false
ldm_ckpt_path: ./savepoint/Letter_high_ldm.pkl

# 训练超参（适度即可，别极端长跑）
learning_rate_ldm: 1.0e-4
weight_decay_ldm: 1.0e-4
num_epochs_ldm: 3000
patience_ldm: 200
ldm_batch_size: 256
ldm_es_interval: 200

# 噪声步数（适度增大，分布更细致）
time_steps: 200
beta_start: 0.0001
beta_end: 0.05

# ===== 新版 LDM 关键参数 =====
ldm_predict: eps               # 'v'（推荐）或 'eps'
ldm_unit_sphere: false
ldm_widths: [256, 512, 512]  # Vector-UNet 宽度层级（x_dim=sample_input_size=256 对齐）
ldm_n_blocks: 2
ldm_use_zero_mlp: false

# 训练期 CFG & 原型一致性（适中）
ldm_p_uncond: 0.2
ldm_lambda_proto: 0.05

# =========================
# 评估/生成（few-shot）相关
# =========================
evaluate_ldm_intrinsic: true
evaluate_ldm_intrinsic_num_samples: 1000

# 采样/评估参数
ldm_guidance: 1.8           # 生成期CFG
ldm_guidance_eval: 0.0      # 内在评估时关闭CFG，避免方差爆
ldm_eval_temp: 0.95         # 内在评估温度（略高一点可改善覆盖）
ldm_eval_simple_var: true  # 评估用“非简单方差”更有多样性

# ===== 测试阶段增强策略（关键）=====
# 先 refine 再 augment（更稳）
refine_first: true
refine_alpha: 0.25

# 每个支持样本生成多少增强（强烈建议小量）
num_augmented_samples: 30

# 生成增强时的采样温度与方差策略（与评估可不同）
ldm_aug_temp: 0.9
ldm_aug_simple_var: false    # 非简方差：多样性更好

# 条件多样性（避免类内塌缩）
aug_mix_alpha: 0.7           # 条件 = 0.6*类均值 + 0.4*同类随机样本
aug_cond_noise_std: 0.10     # 条件上加轻噪声（z 空间）

# 过滤阈值（余弦），更严格：既不过远也不过近
aug_cosine_min_to_proto: 0.3   # 与类原型太远丢
aug_cosine_max_to_nn: 0.9      # 与最近真实样本太近（几乎重复）丢

# 每类增强上限：最多扩到 (1 + ratio) 倍
aug_per_class_max_ratio: 0.5    # 每类最多 +50%

# 线性分类器：真实样本更大权重，生成样本较小权重；少量 MixUp 稳边界
clf_real_weight: 1.0
clf_gen_weight: 0.5
clf_mixup_p: 0.2
clf_mixup_alpha: 0.4

# ===== 任务级微调（Letter_high 建议先关闭；如需再开）=====
task_finetune_steps: 0
task_finetune_lr: 2.0e-4
task_finetune_weight_decay: 1.0e-5
task_finetune_cond_dropout: 0.10
task_finetune_grad_clip: 1.0
task_finetune_patience: 200
task_finetune_warmup_steps: 200
task_lambda_proto: 0.05
task_finetune_accum_steps: 4
task_finetune_micro_repeats: 4
task_finetune_ema_alpha: 0.98

# =========================
# wandb
# =========================
use_wandb: false
wandb_project: "my_fsl_project"
wandb_run_name: "experiment_letter_high_refine_aug"
wandb_entity: "huangyrcn"
wandb_online: true
