import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import random  # ğŸ”§ æ·»åŠ  random æ¨¡å—å¯¼å…¥
import os
from copy import deepcopy
from tqdm import tqdm
import json
import wandb
from sklearn.cluster import KMeans
import warnings

from gin_model import LogReg, Model as GINModel
from models.model import HGINModel
from custom_dataset import CustomDataset
from aug import get_optimized_augmentation  # ä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬
from torch_geometric.data import Data, Batch

from ldm import LDM, finetune_param_filter


class ZScore:
    def __init__(self): 
        self.mu = None
        self.std = None
    
    def fit(self, X, eps=1e-6):
        self.mu = X.mean(0, keepdim=True)
        self.std = (X.var(0, unbiased=False, keepdim=True) + eps).sqrt()
    
    def fwd(self, X): 
        # +1e-12 æå‡æ•°å€¼ç¨³å®šæ€§ï¼ˆä¸ inv å¯¹é½ï¼‰
        return (X - self.mu) / (self.std + 1e-12)
    
    def inv(self, Z): 
        return Z * (self.std + 1e-12) + self.mu

class PyGTrainer:
    """
    PyTorch Geometric Trainer for few-shot learning, using GIN and PyG augmentations.
    Compatible with unified_trainer.py interface.
    """

    def __init__(self, args, logf=None):
        self.args = args
        self.logf = logf

        # åˆå§‹åŒ–ä¿å­˜ç›®å½•
        self.save_dir = "./savepoint"
        os.makedirs(self.save_dir, exist_ok=True)

        # ğŸ¯ å¯¹é½main.py: ç§»é™¤é‡å¤çš„ç§å­è®¾ç½®ï¼Œä¾èµ–main_pyg.pyä¸­çš„å…¨å±€è®¾ç½®

        # ä½¿ç”¨CustomDatasetæ›¿ä»£åŸæ¥çš„Dataset
        self.dataset = CustomDataset(args.dataset_name, args)
        args.train_classes_num = self.dataset.train_classes_num
        args.test_classes_num = self.dataset.test_classes_num

        # ä»å®é™…çš„PyG Dataä¸­è·å–ç‰¹å¾ç»´åº¦
        args.node_fea_size = self.dataset.feature_dim
        print(f"èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {args.node_fea_size}")

        args.N_way = args.test_classes_num

        # Model - æ ¹æ®encodertypeå‚æ•°é€‰æ‹©æ¨¡å‹
        encodertype = getattr(args, 'encodertype', 'gin')  # é»˜è®¤ä¸ºgin
        if encodertype == 'lgin':
            self.model = HGINModel(args).to(args.device)
        else:  # é»˜è®¤ä¸ºgin
            self.model = GINModel(args).to(args.device)
        self.encoder_optimizer = optim.Adam(
            self.model.parameters(), lr=args.lr, weight_decay=args.weight_decay
        )

        # Z-score normalization
        self.use_znorm = bool(not getattr(args, "ldm_unit_sphere", False))
        self.znorm = ZScore() if self.use_znorm else None

        # Evaluation components
        in_dim = self.model.sample_input_emb_size
        num_cls = self.args.N_way
        self.log = LogReg(in_dim, num_cls).to(self.args.device)
        self.xent = nn.CrossEntropyLoss()

        # LDM ç›¸å…³ï¼ˆå»¶è¿Ÿæ„å»ºï¼‰
        self.ldm = None
        self.ldm_optimizer = None

        # è®­ç»ƒé›† embedding/æ¡ä»¶ï¼ˆç”¨äº LDM è®­ç»ƒï¼‰
        self.training_embeddings = None  # raw, unprojected (for LDM)
        self.training_embeddings_proj = None  # projected, for linear probe
        self.training_embeddings_z = None
        self.training_labels = None
        self.kmeans_proto = None  # æ¡ä»¶åŸå‹ï¼ˆz ç©ºé—´ï¼‰
        self.conditions_z = None  # è®­ç»ƒæ¡ä»¶ï¼ˆz ç©ºé—´ï¼‰

        # Graph augmentation for contrastive learning - ä¸main.pyä¿æŒä¸€è‡´
        # modeé€‰é¡¹: 'ultra_fast'(ä»…æµ‹è¯•), 'consistent'(é»˜è®¤ï¼Œæ•°å­¦ä¸€è‡´)
        aug_mode = getattr(args, "aug_mode", "consistent")  # é»˜è®¤æ•°å­¦ä¸€è‡´æ¨¡å¼

        # ğŸ¯ å¯¹é½main.py: ä¸¤ä¸ªå¢å¼ºä½¿ç”¨ç›¸åŒçš„seedç¡®ä¿ä¸€è‡´æ€§
        self.contrastive_aug1 = get_optimized_augmentation(
            aug_type=args.aug1,
            aug_ratio=getattr(args, "aug_ratio", 0.1),
            device=args.device,  # ä¼ é€’è®¾å¤‡å‚æ•°
            seed=args.seed,
            mode=aug_mode,
        )

        self.contrastive_aug2 = get_optimized_augmentation(
            aug_type=args.aug2,
            aug_ratio=getattr(args, "aug_ratio", 0.1),
            device=args.device,  # ä¼ é€’è®¾å¤‡å‚æ•°
            seed=args.seed,  # ğŸ¯ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç›¸åŒseedè€Œä¸æ˜¯seed+1
            mode=aug_mode,
        )

    def train_encoder_contrastive(self):
        """
        é˜¶æ®µ1ï¼šå¯¹æ¯”å­¦ä¹ è®­ç»ƒEncoder (é‡æ„ç‰ˆæœ¬)ã€‚
        - åˆå¹¶äº† _encoder_contrastive_step çš„é€»è¾‘ã€‚
        - å°† DataLoader çš„åˆ›å»ºç§»åˆ°å¾ªç¯å¤–ä»¥æé«˜æ€§èƒ½ã€‚
        """
        print("=== é˜¶æ®µ1ï¼šå¼€å§‹å¯¹æ¯”å­¦ä¹ è®­ç»ƒEncoder (ä¼˜åŒ–ç‰ˆ) ===")

        best_loss = 1e9
        best_epoch = 0
        patience_counter = 0

        encoder_batch_size = getattr(self.args, "encoder_batch_size", 32)
        num_workers = getattr(self.args, "num_workers", 4)

        print(f"è®­ç»ƒå›¾æ•°é‡: {len(self.dataset.train_graphs)}")
        print(f"ç¼–ç å™¨è®­ç»ƒæ‰¹å¤„ç†å¤§å°: {encoder_batch_size}")
        print(f"æ•°æ®åŠ è½½å™¨Workers: {num_workers}")


        for epoch in tqdm(
            range(self.args.epoch_num),
            desc="å¯¹æ¯”å­¦ä¹ è®­ç»ƒEncoder",
            dynamic_ncols=True,
            leave=True,
        ):
            encoder_loader1, encoder_loader2 = self.dataset.aug(
            aug1_type=self.args.aug1,
            aug2_type=self.args.aug2,
            batch_size=encoder_batch_size,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=True,
            seed=self.args.seed,
            aug_ratio=getattr(self.args, "aug_ratio", 0.1),
            )

            self.model.train()  # æ¯ä¸ªepochå¼€å§‹æ—¶è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
            epoch_losses = []

            for batch1, batch2 in zip(encoder_loader1, encoder_loader2):
                if batch1.num_graphs < 2 or batch2.num_graphs < 2:
                    continue
                batch1 = batch1.to(self.args.device, non_blocking=True)
                batch2 = batch2.to(self.args.device, non_blocking=True)
                encoder_embs1 = self.model(batch1)
                encoder_embs2 = self.model(batch2)

                contrastive_loss = self.model.loss_cal(encoder_embs1, encoder_embs2)
                if not torch.isfinite(contrastive_loss):
                    tqdm.write("æ£€æµ‹åˆ° NaN/Inf lossï¼Œæœ¬æ‰¹æ¬¡è·³è¿‡ã€‚")
                    continue

                self.encoder_optimizer.zero_grad()
                contrastive_loss.backward()
                self.encoder_optimizer.step()

                epoch_losses.append(contrastive_loss.item())

            if not epoch_losses:
                tqdm.write(f"Epoch {epoch}: æ²¡æœ‰æœ‰æ•ˆçš„æ‰¹æ¬¡è¿›è¡Œè®­ç»ƒï¼Œè·³è¿‡ã€‚")
                continue

            avg_loss = np.mean(epoch_losses)

            # --- æ—©åœå’Œæ¨¡å‹ä¿å­˜é€»è¾‘ ---
            if avg_loss < best_loss:
                best_loss = avg_loss
                best_epoch = epoch
                patience_counter = 0
                torch.save(
                    self.model.state_dict(),
                    os.path.join(
                        self.save_dir, f"{self.args.dataset_name}_encoder.pkl"
                    ),
                )
            else:
                patience_counter += 1

            if epoch % 10 == 0:  # æ¯10ä¸ªepochæ‰“å°ä¸€æ¬¡
                tqdm.write(
                    f"Epoch {epoch} | Loss: {avg_loss:.4f} | Best Loss: {best_loss:.4f} @ Epoch {best_epoch}"
                )
                if self.logf:
                    self.logf.write(f"Epoch {epoch} Loss {avg_loss:.4f}\n")

            if patience_counter > self.args.patience:
                tqdm.write(f"åœ¨Epoch {epoch}æå‰åœæ­¢!")
                break

        print(f"å¯¹æ¯”å­¦ä¹ è®­ç»ƒå®Œæˆï¼Œæœ€ä½³epoch: {best_epoch}ï¼Œæœ€ä½³loss: {best_loss:.4f}")

    def load_pretrained_encoder(self, ckpt_path=None):
        """ä»å·²ä¿å­˜çš„pklåŠ è½½encoderæƒé‡å¹¶åˆ‡åˆ°evalæ¨¡å¼"""
        if ckpt_path is None:
            ckpt_path = os.path.join(
                self.save_dir, f"{self.args.dataset_name}_encoder.pkl"
            )
        if not os.path.exists(ckpt_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°encoderæƒé‡æ–‡ä»¶: {ckpt_path}")
        try:
            state = torch.load(
                ckpt_path, map_location=self.args.device, weights_only=True
            )
        except TypeError:
            state = torch.load(ckpt_path, map_location=self.args.device)
        self.model.load_state_dict(state)
        self.model.eval()
        print(f"å·²ä» {os.path.basename(ckpt_path)} åŠ è½½Encoderæƒé‡ï¼Œå¹¶åˆ‡æ¢åˆ°evalæ¨¡å¼")

    def test_model(self, num_augmented_samples=0, test_name=None):
        """æµ‹è¯•æ¨¡å‹æ€§èƒ½ - æ­£ç¡®çš„few-shotä»»åŠ¡é‡‡æ ·é€»è¾‘"""
        test_name = test_name or (
            "å¢å¼ºæµ‹è¯•" if num_augmented_samples > 0 else "åŸå§‹Encoderæµ‹è¯•"
        )
        print(f"=== {test_name} ===")

        self.model.eval()
        test_accs = []
        num_test_tasks = self.dataset.test_task_Num  # ä½¿ç”¨é¢„è®¡ç®—çš„æµ‹è¯•ä»»åŠ¡æ•°é‡
        for task_idx in range(num_test_tasks):
            # ä½¿ç”¨ä»»åŠ¡IDç›´æ¥è·å–ä»»åŠ¡ï¼ˆæŒ‰é¡ºåºåˆ’åˆ†ï¼‰
            task_support_graphs, task_query_graphs = self.dataset.sample_one_task(
                task_idx
            )

            # ä¼ é€’å…·ä½“çš„ä»»åŠ¡æ•°æ®ç»™è¯„ä¼°å‡½æ•°
            test_acc = self._evaluate_one_task(
                task_support_graphs, task_query_graphs, num_augmented_samples
            )
            test_accs.append(test_acc)

        avg_acc = np.mean(test_accs) if test_accs else 0.0
        std_acc = np.std(test_accs) if test_accs else 0.0

        print(f"æµ‹è¯•å®Œæˆï¼Œå‡†ç¡®ç‡: {avg_acc:.4f} Â± {std_acc:.4f}")

        return test_accs

    def _evaluate_one_task(self, support_graphs, query_graphs, num_augmented_samples=0):
        """è¯„ä¼°å•ä¸ªfew-shotä»»åŠ¡ - ä½¿ç”¨çœŸå®æ ‡ç­¾ç‰ˆæœ¬"""
        self.model.eval()  # ç¡®ä¿æ¨¡å‹å¤„äºevalæ¨¡å¼

        with torch.no_grad():
            # å‡†å¤‡support set batch
            from torch_geometric.data import Batch

            support_batch = Batch.from_data_list(support_graphs).to(self.args.device)

            # å‡†å¤‡query set batch
            query_batch = Batch.from_data_list(query_graphs).to(self.args.device)

            # å¤„ç†supportå’Œquery set
            support_embs, _ = self.model.sample_input_GNN(support_batch, None)
            query_embs, _ = self.model.sample_input_GNN(query_batch, None)

            # ç›´æ¥ä½¿ç”¨æ•°æ®ä¸­çš„çœŸå®æ ‡ç­¾
            # æ”¯æŒé›†æ ‡ç­¾ï¼ˆåº”è¯¥æ˜¯æœ‰åºçš„ï¼šæ¯ä¸ªç±»åˆ«K_shotä¸ªæ ·æœ¬ï¼‰
            y_support = support_batch.y.to(self.args.device)

            # æŸ¥è¯¢é›†æ ‡ç­¾ï¼ˆå¯èƒ½æ˜¯éšæœºåˆ†å¸ƒçš„ï¼‰
            y_query = query_batch.y.to(self.args.device)

        # é‡æ–°åˆå§‹åŒ–çº¿æ€§åˆ†ç±»å™¨ç¡®ä¿å‚æ•°éœ€è¦æ¢¯åº¦
        from copy import deepcopy

        in_dim = support_embs.size(1)
        temp_log = LogReg(in_dim, self.args.N_way).to(self.args.device)
        opt = torch.optim.SGD(temp_log.parameters(), lr=0.01)

        best_loss, best_state, wait, patience = 1e9, None, 0, 100
        xent = self.xent

        temp_log.train()
        for _ in range(500):
            opt.zero_grad()
            logits = temp_log(support_embs.detach())
            loss_ori = xent(logits, y_support)
            # æ˜¾å¼ L2ï¼ˆä¸åŸç‰ˆä¸€è‡´ï¼‰
            l2 = sum(torch.norm(p) for p in temp_log.parameters())
            loss = loss_ori + 0.1 * l2
            loss.backward()
            opt.step()

            cur = loss.item()
            if cur < best_loss:
                best_loss, best_state, wait = cur, deepcopy(temp_log.state_dict()), 0
            else:
                wait += 1
            if wait > patience:
                break

        if best_state is not None:
            temp_log.load_state_dict(best_state)
        temp_log.eval()
        with torch.no_grad():
            logits = temp_log(query_embs.detach())
            pred = logits.argmax(dim=1)
            acc = (pred == y_query).float().mean().item()

        return acc

    @torch.no_grad()
    def _collect_training_embeddings_pyg(self):
        """ç”¨å½“å‰ Encoder å¯¹è®­ç»ƒå›¾è®¡ç®— embeddingsï¼Œå¹¶åœ¨ z ç©ºé—´æ„æ¡ä»¶åŸå‹ï¼ˆkmeans æˆ–ç±»å‡å€¼ï¼‰"""
        self.model.eval()
        loader = self.dataset.get_encoder_trainloader(
            batch_size=getattr(self.args, "batch_size_for_embedding", 512),
            shuffle=False,
            num_workers=0,
            pin_memory=False,
        )
        embs_raw, embs_proj, lbs = [], [], []
        for batch in loader:
            batch = batch.to(self.args.device, non_blocking=True)
            # Raw pooled features (unprojected) for LDM
            e_raw = self.model.encode_graphs(batch)  # [B, D_raw]
            embs_raw.append(e_raw)
            # Projected features for linear probe
            e_proj = self.model(batch)  # [B, D_proj]
            embs_proj.append(e_proj.detach())
            lbs.append(batch.y)
        self.training_embeddings = torch.cat(embs_raw, 0)  # [N, D_raw]
        self.training_embeddings_proj = torch.cat(embs_proj, 0)  # [N, D_proj]
        self.training_labels = torch.cat(lbs, 0).to(self.args.device)

        if self.use_znorm:
            self.znorm.fit(self.training_embeddings)
            self.training_embeddings_z = self.znorm.fwd(self.training_embeddings)
        else:
            self.training_embeddings_z = self.training_embeddings

        # æ¡ä»¶ï¼šç”¨ç±»å‡å€¼ï¼ˆæ›´ç¨³å®šï¼‰ï¼›å¦‚éœ€ kmeans å¯æ›¿æ¢ä¸º KMeans
        D = self.training_embeddings_z.size(1)
        num_cls = int(self.training_labels.max().item() + 1)
        protos = []
        for c in range(num_cls):
            m = self.training_labels == c
            if m.any():
                protos.append(self.training_embeddings_z[m].mean(0, keepdim=True))
        self.kmeans_proto = torch.cat(protos, 0)  # [C,D]
        self.conditions_z = self.kmeans_proto

    def _build_ldm_pyg(self):
        """æŒ‰é…ç½®æ„å»º LDMï¼ˆä¸ unified_trainer ä¸€è‡´çš„è¶…å‚å‘½åï¼‰"""
        if self.ldm is not None:
            return
        embedding_dim = int(self.model.sample_input_emb_size)
        widths = list(getattr(self.args, "ldm_widths", [256, 512, 512]))
        n_blocks = int(getattr(self.args, "ldm_n_blocks", 2))
        predict_type = str(getattr(self.args, "ldm_predict", "v"))
        unit_sphere = bool(getattr(self.args, "ldm_unit_sphere", False))
        time_steps = int(self.args.time_steps)
        use_zero_mlp = bool(getattr(self.args, "ldm_use_zero_mlp", False))
        device = self.args.device

        # Initialize LDM
        self.ldm = LDM(
            device=device,
            latent_dim=embedding_dim,
            timesteps=time_steps,
            cond_dim=embedding_dim,
            predict=predict_type,
            unit_sphere=unit_sphere,
            self_condition=True,
            widths=widths,
            n_blocks_per_stage=n_blocks,
            use_zero_mlp=use_zero_mlp,
        ).to(device)
        self.ldm_optimizer = optim.AdamW(
            self.ldm.parameters(),
            lr=float(getattr(self.args, "learning_rate_ldm", 1e-4)),
            weight_decay=float(getattr(self.args, "weight_decay_ldm", 1e-4)),
        )

    def train_ldm_pyg(self):
        """è®­ç»ƒ LDMï¼ˆPyG ç‰ˆï¼Œä¸ unified_trainer æµç¨‹ç­‰ä»·ï¼‰"""
        tqdm.write("=== æ”¶é›†è®­ç»ƒé›† embeddingsï¼ˆç”¨äº LDMï¼‰ ===")
        self._collect_training_embeddings_pyg()
        self._build_ldm_pyg()
        tqdm.write("=== å¼€å§‹è®­ç»ƒ LDM ===")
        best = float("inf")
        wait = 0
        patience = int(getattr(self.args, "patience_ldm", 1000))
        es_interval = int(getattr(self.args, "ldm_es_interval", 200))
        T = int(self.args.time_steps)
        p_uncond = float(getattr(self.args, "ldm_p_uncond", 0.3))
        lam_proto = float(getattr(self.args, "ldm_lambda_proto", 0.1))
        bs = int(getattr(self.args, "ldm_batch_size", 512))
        for epoch in tqdm(
            range(1, int(getattr(self.args, "num_epochs_ldm", 30000)) + 1),
            desc="LDM Training",
            ncols=120, dynamic_ncols=True, leave=True
        ):
            # éšæœºå°æ‰¹
            perm = torch.randperm(
                self.training_embeddings_z.size(0), device=self.args.device
            )
            loss_epoch = 0.0
            nstep = 0
            for i in range(0, perm.numel(), bs):
                idx = perm[i : i + bs]
                x0 = self.training_embeddings_z[idx]  # [B,D]
                # é«˜æ•ˆçš„æ¡ä»¶è®¡ç®—ï¼šä½¿ç”¨ç´¢å¼•æ˜ å°„
                cls = self.training_labels[idx]
                cond = self.kmeans_proto[cls]  # ç›´æ¥ç´¢å¼•ï¼Œé¿å…å¾ªç¯

                # æ— æ¡ä»¶ä¸¢å¼ƒ
                m_un = torch.rand(x0.size(0), device=x0.device) < p_uncond
                cond[m_un] = 0.0

                # å‰å‘
                self.ldm_optimizer.zero_grad(set_to_none=True)
                loss = self.ldm.loss(
                    x0, cond, p_uncond=p_uncond, lambda_proto=lam_proto, proto=cond
                )
                loss.backward()
                self.ldm_optimizer.step()
                loss_epoch += loss.item()
                nstep += 1

            avg = loss_epoch / max(1, nstep)
            if wandb.run is not None:
                wandb.log({"ldm_loss": avg}, step=epoch)

            if avg < best:
                best = avg
                wait = 0
                torch.save(
                    self.ldm.state_dict(),
                    os.path.join(self.save_dir, f"{self.args.dataset_name}_ldm.pkl"),
                )
            else:
                wait += 1
            if (wait >= patience) or (epoch % es_interval == 0 and epoch > 0):
                tqdm.write(
                    f"[LDM] epoch={epoch} avg_loss={avg:.4f} best={best:.4f} wait={wait}"
                )
            if wait >= patience:
                tqdm.write("[LDM] Early stop.")
                break

    def load_ldm_pyg(self, path: str):
        self._collect_training_embeddings_pyg()
        self._build_ldm_pyg()
        state = torch.load(path, map_location=self.args.device, weights_only=True)
        self.ldm.load_state_dict(state)
        self.ldm.eval()

    @torch.no_grad()
    def _refine_embeddings_with_ldm(
        self, X: torch.Tensor, y: torch.Tensor, alpha: float = 0.3
    ):
        """è¯„æµ‹æœŸï¼šå…ˆåšä¸€æ¬¡è½»é‡ refineï¼ˆz ç©ºé—´çº¿æ€§æ’å€¼ï¼‰ï¼Œå†å›åŸç©ºé—´"""
        if self.ldm is None:
            return X
        T = int(self.args.time_steps)
        t_ref = max(1, int(0.1 * T))
        Xz = self.znorm.fwd(X) if self.use_znorm else X
        B, D = Xz.size()
        t = torch.full((B,), t_ref, dtype=torch.long, device=X.device)
        # æ¡ä»¶ï¼šåŒç±»å‡å€¼ï¼ˆzï¼‰
        cond = torch.zeros_like(Xz)
        for c in torch.unique(y):
            m = y == c
            if m.any():
                cond[m] = Xz[m].mean(0, keepdim=True)
        x_t, _ = self.ldm.addnoise(Xz, t)
        out = self.ldm._predict_model_out(
            x_t,
            t,
            cond=cond,
            guidance=float(getattr(self.args, "ldm_guidance_eval", 0.0)),
            x0_sc=torch.zeros_like(x_t),
        )
        x0_hat = (
            self.ldm._x0_from_v(x_t, t, out)
            if self.ldm.predict == "v"
            else self.ldm._x0_from_eps(x_t, t, out)
        )
        Xz_ref = (1 - alpha) * Xz + alpha * x0_hat
        return self.znorm.inv(Xz_ref) if self.use_znorm else Xz_ref

    @torch.no_grad()
    def _generate_augmented_embeddings(self, X: torch.Tensor, y: torch.Tensor):
        """
        ç”Ÿæˆå¢å¼ºæ ·æœ¬ï¼ˆz ç©ºé—´é‡‡æ ·ï¼‰+ è´¨é‡è¿‡æ»¤ï¼ˆåŒé˜ˆå€¼ï¼‰+ æ¯ç±»é…é¢ + æ¡ä»¶å¤šæ ·åŒ–
        è¿”å›ï¼šX_all, y_all, n_real
        """
        if (self.ldm is None) or (
            int(getattr(self.args, "num_augmented_samples", 0)) <= 0
        ):
            n_real = X.size(0)
            return X, y, n_real

        # å¯é…ç½®çš„è´¨é‡è¿‡æ»¤é˜ˆå€¼ï¼ˆæå‡æ€§èƒ½å’Œçµæ´»æ€§ï¼‰
        cos_lo = float(
            getattr(self.args, "ldm_filter_cos_lo", 0.15)
        )  # ä¸ç±»åŸå‹æœ€å°ç›¸ä¼¼åº¦
        cos_hi = float(
            getattr(self.args, "ldm_filter_cos_hi", 0.92)
        )  # ä¸æœ€è¿‘çœŸå®æ ·æœ¬æœ€å¤§ç›¸ä¼¼åº¦
        max_ratio = float(
            getattr(self.args, "ldm_aug_max_ratio", 1.50)
        )  # æ¯ç±»æœ€å¤šæ‰©å¢æ¯”ä¾‹
        mix_alpha = float(
            getattr(self.args, "ldm_cond_mix_alpha", 0.30)
        )  # æ¡ä»¶æ··åˆæ¯”ä¾‹
        cond_noise = float(getattr(self.args, "ldm_cond_noise", 0.05))  # æ¡ä»¶å¾®å™ªå£°

        temp = float(getattr(self.args, "ldm_aug_temp", 0.9))
        guid = float(getattr(self.args, "ldm_guidance", 2.5))
        simp = bool(getattr(self.args, "ldm_aug_simple_var", True))
        per_real = int(getattr(self.args, "num_augmented_samples", 0))

        # â†’ z ç©ºé—´
        Xz = self.znorm.fwd(X) if self.use_znorm else X
        D = Xz.size(1)
        y = y.clone()

        # åŸå‹ï¼ˆzï¼‰ï¼šæŒ‰æœ‰åºç±»åˆ—è¡¨æ„å»º
        classes = torch.unique(y, sorted=True)
        protos = [Xz[y == c].mean(0, keepdim=True) for c in classes]
        proto_z = torch.cat(protos, 0)  # [C,D]

        X_aug, y_aug = [], []
        for i, c in enumerate(classes):
            m = y == c
            Xc = Xz[m]  # è¯¥ç±»çœŸå®
            Nc = Xc.size(0)
            quota = min(Nc * per_real, int((1.0 + max_ratio) * Nc) - Nc)
            if quota <= 0:
                continue

            # æ¡ä»¶å¤šæ ·åŒ–ï¼šä¸åŒç±»éšæœºæ ·æœ¬æ··åˆ + å¾®å™ªå£°
            cond = proto_z[i].expand(quota, -1).clone()
            ridx = torch.randint(low=0, high=Nc, size=(quota,), device=Xc.device)
            cond = (1 - mix_alpha) * cond + mix_alpha * Xc[ridx]
            cond = cond + cond_noise * torch.randn_like(cond)

            # é‡‡æ ·
            z_gen = self.ldm.sample(
                shape=(quota, D),
                cond=cond,
                guidance=guid,
                simple_var=simp,
                temp=temp,
                init_match_radius=Xc.norm(dim=1).mean().expand(quota),  # è·ç¦»å°ºåº¦
            )

            # è´¨é‡è¿‡æ»¤ï¼ˆä¸åŸå‹è¿œ/ä¸çœŸå®è¿‡è¿‘ï¼‰
            zp = proto_z[i].expand(quota, -1)
            cos_to_proto = F.cosine_similarity(z_gen, zp, dim=1)
            keep1 = cos_to_proto >= cos_lo
            if keep1.any():
                z_gen = z_gen[keep1]
                quota1 = z_gen.size(0)
                # æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨å½’ä¸€åŒ–å‘é‡è¿›è¡Œä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
                Xc_n = F.normalize(Xc, dim=1)
                z_n = F.normalize(z_gen, dim=1)
                near = (z_n @ Xc_n.t()).max(dim=1).values
                keep2 = near <= cos_hi
                z_gen = z_gen[keep2]
            else:
                z_gen = z_gen[:0]

            if z_gen.numel() == 0:
                continue

            X_aug.append(z_gen)
            y_aug.append(
                torch.full(
                    (z_gen.size(0),), c.item(), dtype=torch.long, device=X.device
                )
            )

        if len(X_aug) == 0:
            print(f"âš ï¸  è­¦å‘Šï¼šæ‰€æœ‰ç”Ÿæˆæ ·æœ¬éƒ½è¢«è´¨é‡è¿‡æ»¤æ‰äº†ï¼Œè€ƒè™‘æ”¾å®½è¿‡æ»¤é˜ˆå€¼")
            n_real = X.size(0)
            return X, y, n_real

        # â† å›åŸç©ºé—´
        Z = torch.cat(X_aug, 0)
        Xg = self.znorm.inv(Z) if self.use_znorm else Z

        X_all = torch.cat([X, Xg], 0)
        y_all = torch.cat([y, torch.cat(y_aug, 0)], 0)
        n_real = X.size(0)

        # æ€§èƒ½ç›‘æ§ä¿¡æ¯
        n_aug = Xg.size(0)
        print(
            f"âœ… å¢å¼ºæ ·æœ¬ç”Ÿæˆ: åŸå§‹={n_real}, ç”Ÿæˆ={n_aug}, æ€»è®¡={X_all.size(0)} (å°†å¤ç”¨äºæ‰€æœ‰æµ‹è¯•ä»»åŠ¡)"
        )

        return X_all, y_all, n_real

    def _train_classifier_weighted(self, X, y, n_real):
        """åŠ æƒ CEï¼ˆçœŸå®æƒé‡å¤§ã€ç”Ÿæˆæƒé‡å°ï¼‰+ å°æ¦‚ç‡ MixUp + åŠ¨æ€è®­ç»ƒæ­¥æ•°"""
        in_dim = X.size(1)
        num_cls = int(self.args.N_way)
        clf = LogReg(in_dim, num_cls).to(self.args.device)
        opt = torch.optim.SGD(clf.parameters(), lr=0.01)
        xent = nn.CrossEntropyLoss(reduction="none")

        # ä¼˜åŒ–çš„è¶…å‚æ•°
        w_real, w_gen = 1.0, 0.7  # æå‡ç”Ÿæˆæ ·æœ¬æƒé‡
        mix_prob, mix_beta = 0.12, 0.2  # ç•¥é™ä½MixUpæ¦‚ç‡

        # åŠ¨æ€è®­ç»ƒæ­¥æ•°ï¼šåŸºäºæ ·æœ¬æ•°é‡è°ƒæ•´
        base_steps = 300
        data_factor = min(2.0, X.size(0) / 50.0)  # æ ·æœ¬è¶Šå¤šï¼Œè®­ç»ƒè¶Šä¹…
        max_steps = int(base_steps * data_factor)

        best, best_state, wait, patience = 1e9, None, 0, max(50, max_steps // 6)

        for step in range(max_steps):
            opt.zero_grad()
            Xb, yb = X, y
            # mixupï¼ˆå°æ¦‚ç‡ï¼‰
            if torch.rand(1).item() < mix_prob:
                lam = torch.distributions.Beta(mix_beta, mix_beta).sample().item()
                perm = torch.randperm(Xb.size(0), device=X.device)
                Xb = lam * Xb + (1 - lam) * Xb[perm]
                y_a, y_b = yb, yb[perm]
            else:
                lam, y_a, y_b = 1.0, yb, yb

            logits = clf(Xb)
            loss_vec = (
                (lam * xent(logits, y_a) + (1 - lam) * xent(logits, y_b))
                if lam < 1.0
                else xent(logits, yb)
            )
            # ä¼˜åŒ–çš„åŠ æƒç­–ç•¥
            w = torch.ones_like(loss_vec)
            w[n_real:] = w_gen
            w[:n_real] = w_real
            loss = (w * loss_vec).mean() + 0.05 * sum(
                torch.norm(p) for p in clf.parameters()
            )  # é™ä½æ­£åˆ™åŒ–
            loss.backward()
            opt.step()
            if loss.item() < best:
                best, best_state, wait = loss.item(), deepcopy(clf.state_dict()), 0
            else:
                wait += 1
            if wait > patience:
                break
        if best_state is not None:
            clf.load_state_dict(best_state)
        clf.eval()
        return clf

    def _sample_test_task(self, task_idx=None):
        """
        ä¸ test_model ä½¿ç”¨ç›¸åŒçš„ä»»åŠ¡é‡‡æ ·æ¥å£ï¼š
        è¿”å› (support_graphs, query_graphs)
        """
        if task_idx is None:
            # ç®€å•è½®è½¬æˆ–éšæœº
            task_idx = random.randint(0, self.dataset.test_task_Num - 1)
        return self.dataset.sample_one_task(task_idx)

    def test_model_with_ldm_pyg(self, num_test=20):
        """few-shot æµ‹è¯•ï¼ˆä¸€æ¬¡å¢å¼ºï¼Œå¤šæ¬¡å¤ç”¨ï¼‰"""
        self.model.eval()
        self._build_ldm_pyg()

        # ç¡®è®¤LDMå·²è®­ç»ƒæˆ–åŠ è½½
        if self.ldm is None:
            raise RuntimeError(
                "LDM å°šæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ train_ldm_pyg() æˆ– load_ldm_pyg()"
            )

        # === ä¸€æ¬¡æ€§ç”Ÿæˆå¢å¼ºæ”¯æŒé›†ï¼ˆæ”¯æŒé›†å›ºå®šä¸å˜ï¼‰ ===
        support_graphs, _ = self._sample_test_task(0)  # è·å–å›ºå®šæ”¯æŒé›†
        with torch.no_grad():
            s_batch = Batch.from_data_list(support_graphs).to(self.args.device)
            Xs = self.model.encode_graphs(s_batch)  # [S,D]
            ys = torch.tensor(
                [g.label for g in support_graphs], device=self.args.device
            ).long()

        # ä¸€æ¬¡æ€§ç”Ÿæˆå¢å¼ºæ•°æ®
        print("ğŸš€ å¼€å§‹ä¸€æ¬¡æ€§ç”Ÿæˆå¢å¼ºæ”¯æŒé›†...")
        Xs_ref = self._refine_embeddings_with_ldm(Xs, ys, alpha=0.3)
        Xtrain_cached, ytrain_cached, n_real_cached = (
            self._generate_augmented_embeddings(Xs_ref, ys)
        )
        print(f"âœ… å¢å¼ºæ”¯æŒé›†ç”Ÿæˆå®Œæˆï¼Œå°†å¤ç”¨äºæ‰€æœ‰ {num_test} ä¸ªæµ‹è¯•ä»»åŠ¡")

        # === å¯¹æ¯ä¸ªæµ‹è¯•ä»»åŠ¡ä½¿ç”¨ç›¸åŒçš„å¢å¼ºæ”¯æŒé›† ===
        accs = []
        for test_i in range(num_test):
            # åªè·å–ä¸åŒçš„æŸ¥è¯¢é›†
            _, query_graphs = self._sample_test_task(test_i)

            # ç¼–ç æŸ¥è¯¢é›†
            with torch.no_grad():
                q_batch = Batch.from_data_list(query_graphs).to(self.args.device)
                Xq = self.model.encode_graphs(q_batch)  # [Q,D]
                yq = torch.tensor(
                    [g.label for g in query_graphs], device=self.args.device
                ).long()

            # ä½¿ç”¨ç¼“å­˜çš„å¢å¼ºæ”¯æŒé›†è®­ç»ƒåˆ†ç±»å™¨
            clf = self._train_classifier_weighted(
                Xtrain_cached, ytrain_cached, n_real_cached
            )

            # è¯„æµ‹
            with torch.no_grad():
                logits = clf(Xq)
                pred = logits.argmax(dim=1)
                acc = (pred == yq).float().mean().item()
            accs.append(acc)

        accs = np.array(accs)
        return float(accs.mean()), float(accs.std())

    # å¯ä»¥æ·»åŠ å…¶ä»–æ–¹æ³•ï¼Œå¦‚LDMç›¸å…³çš„è®­ç»ƒç­‰
